import argparse
import json
from collections import defaultdict

import pandas as pd


def normalize_name(name: str, name_map: dict) -> str:
    return name_map.get(name, name)


def apply_replacement_rules(station_name: str, line_cds: set, replacement_rules: list, major_lines: dict) -> str:
    """
    é§…åã«å¯¾ã—ã¦replacement_rulesã‚’é©ç”¨ã™ã‚‹
    
    Args:
        station_name: å¯¾è±¡ã®é§…å
        line_cds: ãã®é§…ãŒé€šã£ã¦ã„ã‚‹è·¯ç·šã‚³ãƒ¼ãƒ‰ã®set
        replacement_rules: ç½®æ›ãƒ«ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆ
        major_lines: æœ‰åŠ¹ãªè·¯ç·šã‚³ãƒ¼ãƒ‰ã®dict
        
    Returns:
        ç½®æ›å¾Œã®é§…å
        
    Raises:
        ValueError: targetã«ãƒãƒƒãƒã—ãŸãŒã©ã®ruleã«ã‚‚ãƒãƒƒãƒã—ãªã‹ã£ãŸå ´åˆ
    """
    for rule in replacement_rules:
        if station_name == rule["target"]:
            for line_rule in rule["rules"]:
                rule_line_cds = set(line_rule["lines"])
                # ãã®é§…ãŒé€šã£ã¦ã„ã‚‹è·¯ç·šã‚³ãƒ¼ãƒ‰ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                station_line_cds = {str(cd) for cd in line_cds}
                if rule_line_cds.intersection(station_line_cds):
                    return line_rule["dest"]
            # targetã«ãƒãƒƒãƒã—ãŸãŒã©ã®ruleã«ã‚‚ãƒãƒƒãƒã—ãªã‹ã£ãŸå ´åˆ
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¨ã—ã¦æ–‡å­—åˆ—å¤‰æ›ã—ãŸè·¯ç·šã‚³ãƒ¼ãƒ‰ã‚‚è¡¨ç¤º
            valid_line_cds_str = {str(cd) for cd in line_cds if str(cd) in major_lines}
            raise ValueError(f"Station '{station_name}' matched target but no replacement rule matched. Line codes: {line_cds}, Valid line codes: {valid_line_cds_str}")
    return station_name


def build_base_graph(config: dict, stations, joins, lines):
    major_lines = config["lines"]
    normalize_name_map = config["normalize_name_map"]
    replacement_rules = config.get("replacement_rules", [])
    valid_pref_cds = set(config["valid_pref_cds"])

    filtered_stations = stations[stations["pref_cd"].isin(valid_pref_cds)]
    cd_to_name = filtered_stations.set_index("station_cd")["station_name"].to_dict()
    valid_station_cds = set(cd_to_name.keys())

    station_pos = filtered_stations.set_index("station_cd")[["lon", "lat"]].to_dict(
        orient="index"
    )

    # å„é§…ãŒé€šã£ã¦ã„ã‚‹è·¯ç·šã‚³ãƒ¼ãƒ‰ã‚’äº‹å‰ã«è¨ˆç®—
    station_lines = defaultdict(set)
    for _, row in joins.iterrows():
        cd1, cd2, line_cd = row["station_cd1"], row["station_cd2"], row["line_cd"]
        if cd1 in valid_station_cds and cd2 in valid_station_cds:
            station_lines[cd1].add(line_cd)
            station_lines[cd2].add(line_cd)

    graph = defaultdict(lambda: {"lat": None, "lon": None, "edges": []})

    for _, row in joins.iterrows():
        cd1, cd2, line_cd = row["station_cd1"], row["station_cd2"], row["line_cd"]

        if cd1 in valid_station_cds and cd2 in valid_station_cds:
            name1 = normalize_name(cd_to_name[cd1], normalize_name_map)
            name2 = normalize_name(cd_to_name[cd2], normalize_name_map)
            
            # replacement_rulesã‚’é©ç”¨
            name1 = apply_replacement_rules(name1, station_lines[cd1], replacement_rules, major_lines)
            name2 = apply_replacement_rules(name2, station_lines[cd2], replacement_rules, major_lines)

            if str(line_cd) not in major_lines:
                continue

            line_name = major_lines[str(line_cd)]

            if graph[name1]["lat"] is None or graph[name1]["lon"] is None:
                pos1 = station_pos.get(cd1)
                if pos1:
                    graph[name1]["lat"] = pos1["lat"]
                    graph[name1]["lon"] = pos1["lon"]

            if graph[name2]["lat"] is None or graph[name2]["lon"] is None:
                pos2 = station_pos.get(cd2)
                if pos2:
                    graph[name2]["lat"] = pos2["lat"]
                    graph[name2]["lon"] = pos2["lon"]

            graph[name1]["edges"].append(
                {
                    "station": name2,
                    "line": line_name,
                    "station_cd": str(cd2),
                    "line_cd": str(line_cd),
                }
            )
            graph[name2]["edges"].append(
                {
                    "station": name1,
                    "line": line_name,
                    "station_cd": str(cd1),
                    "line_cd": str(line_cd),
                }
            )

    return graph


def add_walking_connections(graph: dict, walking_pairs: list) -> dict:
    def ensure_entry(station_name):
        if station_name not in graph:
            graph[station_name] = {"lat": None, "lon": None, "edges": []}

    def connection_exists(from_station, to_station):
        return any(
            conn["station"] == to_station and conn["line"] == "å¾’æ­©"
            for conn in graph[from_station].get("edges", [])
        )

    for s1, s2 in walking_pairs:
        ensure_entry(s1)
        ensure_entry(s2)

        if not connection_exists(s1, s2):
            graph[s1]["edges"].append(
                {
                    "station": s2,
                    "line": "å¾’æ­©",
                    "station_cd": "",
                    "line_cd": "",
                }
            )

        if not connection_exists(s2, s1):
            graph[s2]["edges"].append(
                {
                    "station": s1,
                    "line": "å¾’æ­©",
                    "station_cd": "",
                    "line_cd": "",
                }
            )

    return graph


def main(config_path: str, base_output: str, walking_output: str):
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    stations = pd.read_csv("data/v2/station.csv")
    joins = pd.read_csv("data/v2/join.csv")
    lines = pd.read_csv("data/v2/line.csv")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    with open(config_path, encoding="utf-8") as f:
        config = json.load(f)

    # ãƒ™ãƒ¼ã‚¹ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    graph = build_base_graph(config, stations, joins, lines)

    with open(base_output, "w", encoding="utf-8") as f:
        json.dump(graph, f, ensure_ascii=False, indent=2)
    print(f"âœ… ãƒ™ãƒ¼ã‚¹ã‚°ãƒ©ãƒ•ã‚’ {base_output} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    # å¾’æ­©æ¥ç¶šè¿½åŠ 
    walking_pairs = config.get("walking_pairs", [])
    graph_with_walking = add_walking_connections(graph, walking_pairs)

    with open(walking_output, "w", encoding="utf-8") as f:
        json.dump(graph_with_walking, f, ensure_ascii=False, indent=2)
    print(f"ğŸš¶ å¾’æ­©æ¥ç¶šã‚°ãƒ©ãƒ•ã‚’ {walking_output} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é§…ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆï¼ˆå¾’æ­©æ¥ç¶šä»˜ãï¼‰")
    parser.add_argument("--config", required=True, help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument(
        "--base_output", default="graph_with_pos.json", help="ãƒ™ãƒ¼ã‚¹ã‚°ãƒ©ãƒ•å‡ºåŠ›å…ˆ"
    )
    parser.add_argument(
        "--walking_output",
        default="graph_with_pos_walking.json",
        help="å¾’æ­©æ¥ç¶šã‚°ãƒ©ãƒ•å‡ºåŠ›å…ˆ",
    )

    args = parser.parse_args()
    main(args.config, args.base_output, args.walking_output)
